{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Pre-processing and Transformation\n",
    "\n",
    "Python program to pre-process and transform the dataset into a format suitable for developing machine learning models. For feature selection, using the filter method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gwp_pipeline import gwp_pipeline\n",
    "from star_pipeline import star_pipeline\n",
    "import processing as pr\n",
    "import selection as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickolaitchesnokov/Desktop/Code/Projects/data_mining/processing.py:12: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt(csv_file, delimiter=',', dtype=None, names=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2015, 1,  1, 0., 1., 3.,  8., 0.8 , 26.16,  1.108e+03, 7080., 98., 0.,  0., 0., 59. , 0.94072542)\n",
      " (2015, 1,  1, 0., 0., 3.,  1., 0.75,  3.94, -1.000e+00,  960.,  0., 0.,  0., 0.,  8. , 0.8865    )\n",
      " (2015, 1,  1, 0., 1., 3., 11., 0.8 , 11.41,  9.680e+02, 3660., 50., 0.,  0., 0., 30.5, 0.80057049)\n",
      " ...\n",
      " (2015, 3, 11, 1., 0., 5.,  7., 0.65,  3.9 , -1.000e+00,  960.,  0., 0., -1., 0.,  8. , 0.625625  )\n",
      " (2015, 3, 11, 1., 0., 5.,  9., 0.75,  2.9 , -1.000e+00, 1800.,  0., 0.,  0., 0., 15. , 0.50588889)\n",
      " (2015, 3, 11, 1., 0., 5.,  6., 0.7 ,  2.9 , -1.000e+00,  720.,  0., 0.,  0., 0.,  6. , 0.39472222)]\n",
      "[('year', '<i8'), ('month', '<i8'), ('day_of_month', '<i8'), ('quarter', '<f8'), ('department', '<f8'), ('day', '<f8'), ('team', '<f8'), ('targeted_productivity', '<f8'), ('smv', '<f8'), ('wip', '<f8'), ('over_time', '<f8'), ('incentive', '<f8'), ('idle_time', '<f8'), ('idle_men', '<f8'), ('no_of_style_change', '<f8'), ('no_of_workers', '<f8'), ('actual_productivity', '<f8')]\n",
      "\n",
      "\n",
      "[(1.23766096e+18, 135.6891066 , 32.49463184, 23.87882, 22.2753 , 20.39501, 19.16573, 18.79371, 3606., 301., 2.,  79., 6.54377737e+18, 0.6347936,  5812., 56354., 171., b'GALAXY')\n",
      " (1.23766488e+18, 144.82610055, 31.27418489, 24.77759, 22.83188, 22.58444, 21.16812, 21.61427, 4518., 301., 5., 119., 1.17601420e+19, 0.779136 , 10445., 58158., 427., b'GALAXY')\n",
      " (1.23766096e+18, 142.18878956, 35.58244418, 25.26307, 22.66389, 20.60976, 19.34857, 18.94827, 3606., 301., 2., 120., 5.15220026e+18, 0.6441945,  4576., 55592., 299., b'GALAXY')\n",
      " ...\n",
      " (1.23766830e+18, 224.58740744, 15.70070739, 21.16916, 19.26997, 18.20428, 17.69034, 17.35221, 5314., 301., 4., 308., 3.11200776e+18, 0.1433656,  2764., 54535.,  74., b'GALAXY')\n",
      " (1.23766115e+18, 212.26862112, 46.66036528, 25.35039, 21.63757, 19.91386, 19.07254, 18.62482, 3650., 301., 4., 131., 7.60107957e+18, 0.4550396,  6751., 56368., 470., b'GALAXY')\n",
      " (1.23766115e+18, 196.89605297, 49.46464277, 22.62171, 21.79745, 20.60115, 20.00959, 19.28075, 3650., 301., 4.,  60., 8.34315235e+18, 0.5429442,  7410., 57104., 851., b'GALAXY')]\n",
      "[('obj_ID', '<f8'), ('alpha', '<f8'), ('delta', '<f8'), ('u', '<f8'), ('g', '<f8'), ('r', '<f8'), ('i', '<f8'), ('z', '<f8'), ('run_ID', '<f8'), ('rerun_ID', '<f8'), ('cam_col', '<f8'), ('field_ID', '<f8'), ('spec_obj_ID', '<f8'), ('redshift', '<f8'), ('plate', '<f8'), ('MJD', '<f8'), ('fiber_ID', '<f8'), ('class', 'S6')]\n"
     ]
    }
   ],
   "source": [
    "gwp_csv = 'datasets/gwp_assessment.csv'\n",
    "star_csv = 'datasets/star_assessment.csv'\n",
    "\n",
    "# Load data from csv\n",
    "gwp_data = pr.read_csv(gwp_csv)\n",
    "star_data = pr.read_csv(star_csv)\n",
    "\n",
    "# Process data\n",
    "gwp_dataset = gwp_pipeline(gwp_data)\n",
    "star_dataset = star_pipeline(star_data)\n",
    "\n",
    "print(gwp_dataset)\n",
    "print(gwp_dataset.dtype)\n",
    "print(\"\\n\")\n",
    "print(star_dataset)\n",
    "print(star_dataset.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "SEED = 40\n",
    "\n",
    "# Initialise list of features to drop\n",
    "gwp_dropped_features = []\n",
    "\n",
    "# Split feature and target sets\n",
    "X, y = pr.split_features_and_target(gwp_dataset)\n",
    "X_names, y_name = pr.get_feature_and_target_names(gwp_dataset)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Normalise the data \n",
    "X_train_norm, X_test_norm = sl.normalize_data(X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
